(window.webpackJsonp=window.webpackJsonp||[]).push([[49],{460:function(s,t,a){"use strict";a.r(t);var n=a(2),e=Object(n.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h1",{attrs:{id:"卷积神经网络"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#卷积神经网络"}},[s._v("#")]),s._v(" 卷积神经网络")]),s._v(" "),t("h2",{attrs:{id:"_1-背景"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-背景"}},[s._v("#")]),s._v(" 1. 背景")]),s._v(" "),t("p",[s._v("使用全连接神经网络处理图像问题时，往往存在以下三个缺陷：")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("参数过多")]),s._v(" "),t("p",[s._v("随着"),t("strong",[s._v("隐藏层神经元数量的增多")]),s._v("，参数的规模也会急剧增加，导致整个神经网络的成本很高，训练效率非常低，且容易出现过拟合。")])]),s._v(" "),t("li",[t("p",[s._v("难以捕捉局部特征")]),s._v(" "),t("p",[s._v("全连接前馈网络"),t("strong",[s._v("很难提取局部不变性特征")]),s._v("（比如尺度缩放、平移、旋转等操作不影响其语义信息），一般需要进行数据增强来提高其性能。")])]),s._v(" "),t("li",[t("p",[s._v("导致信息缺失")]),s._v(" "),t("p",[s._v("由于全连接神经网络在处理图像信息时，首先需要将图像展开为向量，因此"),t("strong",[s._v("部分空间信息容易丢失")]),s._v("，导致图像识别的准确率不高。")])])]),s._v(" "),t("p",[s._v("受到生物学上的感受野机制的启发，提出了卷积神经网络（Convolutional Neural Network，CNN）。")]),s._v(" "),t("h2",{attrs:{id:"_2-核心思想"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-核心思想"}},[s._v("#")]),s._v(" 2. 核心思想")]),s._v(" "),t("p",[s._v("通过建立卷积层、池化层以及全连接层实现对图像的精确处理。")]),s._v(" "),t("ul",[t("li",[s._v("卷积层负责提取图像中的局部特征")]),s._v(" "),t("li",[s._v("池化层大幅降低参数数量（降维）从而提高训练效率")]),s._v(" "),t("li",[s._v("全连接层进行线性转换，输出结果")])]),s._v(" "),t("p",[s._v("卷积神经网络在结构上有局部连接（一片一片的乘积）、权值共享（卷积核）和池化三个特性，因此在图像处理上有很大优势。")]),s._v(" "),t("h2",{attrs:{id:"_3-常用术语"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-常用术语"}},[s._v("#")]),s._v(" 3. 常用术语")]),s._v(" "),t("p",[t("img",{attrs:{src:"markdown-img/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.assets/image-20250512170442030.png",alt:"image-20250512170442030"}})]),s._v(" "),t("h3",{attrs:{id:"卷积-convolution"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#卷积-convolution"}},[s._v("#")]),s._v(" 卷积 convolution")]),s._v(" "),t("p",[s._v("对图像（不同的数据窗口数据）和滤波矩阵（一组固定的权重）做矩阵内积（对应元素相乘再求和）的操作就是所谓的“卷积”。")]),s._v(" "),t("h3",{attrs:{id:"步长stride"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#步长stride"}},[s._v("#")]),s._v(" 步长stride")]),s._v(" "),t("p",[s._v("即移动的步长")]),s._v(" "),t("h3",{attrs:{id:"池化pooling"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#池化pooling"}},[s._v("#")]),s._v(" 池化pooling")]),s._v(" "),t("p",[s._v("分最大池化、平均池化。作矩阵内积时，分别选取图像对应矩阵中最大值、平均值。就是取区域最大或者区域平均。")]),s._v(" "),t("p",[t("img",{attrs:{src:"markdown-img/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.assets/image-20250512170313026.png",alt:"image-20250512170313026"}})]),s._v(" "),t("p",[s._v("作用：")]),s._v(" "),t("ol",[t("li",[s._v("保留图像的重要特征")]),s._v(" "),t("li",[s._v("数据降维")])]),s._v(" "),t("h3",{attrs:{id:"滤波器filter"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#滤波器filter"}},[s._v("#")]),s._v(" 滤波器filter")]),s._v(" "),t("p",[s._v("即滤波矩阵W0、W1")]),s._v(" "),t("h3",{attrs:{id:"卷积核kernel"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#卷积核kernel"}},[s._v("#")]),s._v(" 卷积核Kernel")]),s._v(" "),t("p",[s._v("即W0、W1下的3个红色、粉红色矩阵")]),s._v(" "),t("h3",{attrs:{id:"补全padding"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#补全padding"}},[s._v("#")]),s._v(" 补全padding")]),s._v(" "),t("p",[s._v("即为了得到其他维度的结果，周围一圈按情况补0。")]),s._v(" "),t("h3",{attrs:{id:"channel"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#channel"}},[s._v("#")]),s._v(" channel")]),s._v(" "),t("p",[s._v("即一个图像")]),s._v(" "),t("h2",{attrs:{id:"_4-一维卷积"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-一维卷积"}},[s._v("#")]),s._v(" 4. 一维卷积")]),s._v(" "),t("p",[s._v("卷积核仅沿一个方向移动。")]),s._v(" "),t("h3",{attrs:{id:"代码示例"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#代码示例"}},[s._v("#")]),s._v(" 代码示例")]),s._v(" "),t("p",[s._v("以2016年北京地铁西直门站每15min客流的进站数据为例，利用PyTorch搭建一维卷积神经网络，实现对进站客流数据的预测。")]),s._v(" "),t("ol",[t("li",[s._v("导包")])]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" torch\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("nn "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" nn\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" matplotlib"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("pyplot "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" plt\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" numpy "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" np\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" pandas "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" pd\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" sklearn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("preprocessing "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" MinMaxScaler\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" numpy"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("lib"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("stride_tricks "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" sliding_window_view\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br")])]),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[s._v("path "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'./卷积神经网络/15min_in.csv'")]),s._v("\ndf "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" pd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("read_csv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("path"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" encoding"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'gbk'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" parse_dates"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\ndata "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'西直门'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("values"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("astype"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'float32'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\nplt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("plot"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("data"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nplt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("show"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br")])]),t("p",[s._v("​"),t("br"),s._v(" "),t("img",{attrs:{src:"markdown-img/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.assets/%E4%B8%80%E7%BB%B4%E5%8D%B7%E7%A7%AF_4_0.png",alt:"png"}}),s._v("\n​")]),s._v(" "),t("ol",{attrs:{start:"2"}},[t("li",[s._v("拆分数据集")])]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("len")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("data"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nsplit_num "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("300")]),s._v("\ntrain "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" data"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("split_num"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\ntest "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" data"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("split_num"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br")])]),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[s._v("1800\n")])])]),t("ol",{attrs:{start:"3"}},[t("li",[s._v("归一化，按时间窗初始化数据")])]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v("'''\n归一化\n'''")]),s._v("\nscaler "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" MinMaxScaler"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("feature_range"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\ntrain_norm "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" scaler"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fit_transform"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("train"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("reshape"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\ntest_norm "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" scaler"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fit_transform"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("test"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("reshape"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 转tensor并摊开")]),s._v("\ntrain_set "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("FloatTensor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("train_norm"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("view"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\ntest_set "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("FloatTensor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("test_norm"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("view"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v("'''\n样本提取（时间窗）\n从原时间序列中抽取出训练样本，用第1个值到第72个值作为X输入，预测第73个值作为y输出\n'''")]),s._v("\nTime_window_size "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("72")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("input_data")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("seq"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" ws"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("  \n    out "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n    L "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("len")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("seq"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("range")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("L"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("ws"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        window "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" seq"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("i "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" ws"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n        label "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" seq"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("i "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" ws"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("i "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" ws "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n        out"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("append"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("window"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" label"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" out\ntrain_data "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" input_data"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("train_set"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" Time_window_size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\ntest_data "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" input_data"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("test_set"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" Time_window_size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br")])]),t("ol",{attrs:{start:"4"}},[t("li",[s._v("模型搭建")])]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v("'''\n模型搭建\n'''")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("CNN_NETWORK")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Module"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("__init__")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("super")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("CNN_NETWORK"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("__init__"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 使用64个卷积核，大小为2，在一维序列上进行一维卷积")]),s._v("\n        self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("conv1d "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Conv1d"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("in_channels"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" out_channels"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("64")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" kernel_size"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 激活函数：为卷积输出引入非线性")]),s._v("\n        self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("relu "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ReLU"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("inplace"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 使用32个卷积核，大小为2，在64维序列上进行一维卷积")]),s._v("\n        self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("conv1d2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Conv1d"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("in_channels"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("64")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" out_channels"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("32")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" kernel_size"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 一维最大池化层，窗口大小 2、步幅 2，将时序长度缩减一半，突出最显著特征并降低计算量。")]),s._v("\n        self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("pool "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("MaxPool1d"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("kernel_size"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" stride"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fc1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Linear"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("32")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("35")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("640")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fc2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Linear"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("640")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Dropout 层，训练时随机丢弃 50% 的神经元，防止过拟合。")]),s._v("\n        self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("drop "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Dropout"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    \n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("forward")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v("'''\n        x [1,1,72] -> [1,64,71]\n        input N(batch) Cin(seq) Lin(size) \n        '''")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("conv1d"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 激活函数，shape不变")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("relu"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v("'''\n        x [1,64,71] -> [1,32,70]\n        '''")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("conv1d2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("relu"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v("'''\n        x [1,32,70] -> [1,32,35]\n        '''")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("pool"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("drop"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v("'''\n        x [1,32,35] -> [1120]\n        '''")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("view"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v("'''\n        x [1120] -> 640\n        '''")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fc1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("relu"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v("'''\n        x [1120] -> 640\n        '''")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fc2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" x\n\ndevice "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("device"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"cuda"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nnet "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" CNN_NETWORK"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("to"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("device"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("device"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br"),t("span",{staticClass:"line-number"},[s._v("34")]),t("br"),t("span",{staticClass:"line-number"},[s._v("35")]),t("br"),t("span",{staticClass:"line-number"},[s._v("36")]),t("br"),t("span",{staticClass:"line-number"},[s._v("37")]),t("br"),t("span",{staticClass:"line-number"},[s._v("38")]),t("br"),t("span",{staticClass:"line-number"},[s._v("39")]),t("br"),t("span",{staticClass:"line-number"},[s._v("40")]),t("br"),t("span",{staticClass:"line-number"},[s._v("41")]),t("br"),t("span",{staticClass:"line-number"},[s._v("42")]),t("br"),t("span",{staticClass:"line-number"},[s._v("43")]),t("br"),t("span",{staticClass:"line-number"},[s._v("44")]),t("br"),t("span",{staticClass:"line-number"},[s._v("45")]),t("br"),t("span",{staticClass:"line-number"},[s._v("46")]),t("br"),t("span",{staticClass:"line-number"},[s._v("47")]),t("br"),t("span",{staticClass:"line-number"},[s._v("48")]),t("br"),t("span",{staticClass:"line-number"},[s._v("49")]),t("br"),t("span",{staticClass:"line-number"},[s._v("50")]),t("br"),t("span",{staticClass:"line-number"},[s._v("51")]),t("br"),t("span",{staticClass:"line-number"},[s._v("52")]),t("br"),t("span",{staticClass:"line-number"},[s._v("53")]),t("br"),t("span",{staticClass:"line-number"},[s._v("54")]),t("br"),t("span",{staticClass:"line-number"},[s._v("55")]),t("br")])]),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[s._v("cuda\n")])])]),t("ol",{attrs:{start:"5"}},[t("li",[s._v("模型训练")])]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v("'''\n模型训练\n'''")]),s._v("\ncriterion "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("MSELoss"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\noptimizer "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("optim"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Adam"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("parameters"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" lr"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.0005")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\nepoch "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" e "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("range")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("epoch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" seq"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y_train "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" train_data"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        optimizer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("zero_grad"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        y_train "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" y_train"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("to"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("device"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        seq "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" seq"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("reshape"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("to"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("device"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        y_pre "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("seq"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        loss_val "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" criterion"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("y_pre"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("y_train"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        loss_val"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("backward"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        optimizer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("step"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string-interpolation"}},[t("span",{pre:!0,attrs:{class:"token string"}},[s._v("f'epoch:")]),t("span",{pre:!0,attrs:{class:"token interpolation"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("e"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")])]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v(",loss:")]),t("span",{pre:!0,attrs:{class:"token interpolation"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("loss_val"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")])]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br")])]),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[s._v("epoch:0,loss:0.00025611836463212967\nepoch:1,loss:0.03752532973885536\n")])])]),t("ol",{attrs:{start:"6"}},[t("li",[s._v("画图")])]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[s._v("test_seq "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("FloatTensor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("test"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nrealVal "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\npreVal "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("with")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("no_grad"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("eval")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" seq"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y_test "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" test_data"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        seq "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" seq"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("reshape"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("to"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("device"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        test_pre "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("seq"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        realVal"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("append"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("y_test"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("numpy"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 注意要把cuda变量扔回cpu")]),s._v("\n        preVal"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("append"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("test_pre"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("cpu"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("numpy"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\nplt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("figure"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("figsize"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nplt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("plot"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("realVal"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" label"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'real'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nplt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("plot"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("preVal"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" label"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'pre'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nplt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("legend"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nplt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("show"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br")])]),t("p",[t("img",{attrs:{src:"markdown-img/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.assets/%E4%B8%80%E7%BB%B4%E5%8D%B7%E7%A7%AF_14_0.png",alt:"png"}})]),s._v(" "),t("h2",{attrs:{id:"_5-二维卷积"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5-二维卷积"}},[s._v("#")]),s._v(" 5. 二维卷积")]),s._v(" "),t("p",[s._v("卷积核仅沿2个方向移动。")]),s._v(" "),t("h3",{attrs:{id:"代码示例-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#代码示例-2"}},[s._v("#")]),s._v(" 代码示例")]),s._v(" "),t("p",[s._v("使用PyTorch搭建二维卷积神经网络，用来识别MNIST手写数字数据集，对手写数字进行分类。")]),s._v(" "),t("p",[t("code",[s._v("transforms.Compose([...])")])]),s._v(" "),t("p",[s._v("这是一个组合多个变换操作的容器。这里的操作会按顺序依次作用在输入的图像上。")]),s._v(" "),t("p",[s._v("MNIST数据集包含了60000个训练集和10000个测试数据集，分为图片和标签。图片是28×28的像素矩阵，每张图片是一个手写数字（0 到 9 之间）。标签为0~9共10个数字。")]),s._v(" "),t("p",[t("img",{attrs:{src:"markdown-img/%E4%BA%8C%E7%BB%B4%E5%8D%B7%E7%A7%AF.assets/898dcc3e-7106-4eda-981c-3b24a7622b00.png",alt:"image.png"}})]),s._v(" "),t("ol",[t("li",[s._v("初始化数据")])]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" matplotlib"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("pyplot "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" plt\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" numpy "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" np\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" torch\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("nn "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" nn\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" PIL "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Image\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" torchvision\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" torchvision"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("transforms "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" transforms\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("utils"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" Data\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("optim "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" optim\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getDataLoader")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("is_train"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    batch_size "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("512")]),s._v("\n    tra "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" transforms"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Compose"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n        transforms"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ToTensor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 把图像转为Tensor")]),s._v("\n        transforms"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Normalize"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("mean"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" std"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 归一化")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    dataset "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torchvision"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("datasets"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("MNIST"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("root"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'./卷积神经网络/Datasets/MNIST'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" train"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("is_train"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" transform"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("tra"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("download"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("False")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# num_workers = 0表示不需要多线程工作")]),s._v("\n    loader "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Data"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("DataLoader"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("dataset"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("batch_size"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("batch_size"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("shuffle"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" num_workers"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" loader\n\ntrain_loader "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" getDataLoader"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\ntest_loader "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" getDataLoader"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("False")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br")])]),t("ol",{attrs:{start:"2"}},[t("li",[s._v("初始化模型")])]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 卷积层")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Conv2dModule")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Module"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# def __init__(self):")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#     super(Conv2dModule,self).__init__()")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#     self.conv2d = nn.Sequential(")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#         # 第一层")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#         nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3,stride=1, padding=1),")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#         # 从每个局部区域中提取最大值，从而降低特征图尺寸，保留主要特征，减少计算。")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#         nn.MaxPool2d(kernel_size=2, stride=2),")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#         nn.ReLU(inplace=True),")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#         # 第二层")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#         nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3,stride=1, padding=1),")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#         nn.MaxPool2d(kernel_size=2, stride=2),")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#         nn.ReLU(inplace=True),")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#     )")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#     self.relu = nn.ReLU()")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("__init__")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("super")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Conv2dModule"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("__init__"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Conv2d_1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Conv2d"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("in_channels"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" out_channels"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("32")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" kernel_size"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("stride"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" padding"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("MaxPool2d "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("MaxPool2d"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("kernel_size"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" stride"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ReLU "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ReLU"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("inplace"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Conv2d_2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Conv2d"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("in_channels"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("32")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" out_channels"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("64")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" kernel_size"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("stride"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" padding"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fc1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Linear"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("64")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("14")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("14")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1024")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fc2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Linear"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1024")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("512")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fc3 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Linear"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("512")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" num_classes"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("num "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n    \n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("forward")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 64 1 28 28 -> 64 32 28 28")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Conv2d_1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 64 32 28 28 -> 64 32 14 14")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ReLU"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 64 32 14 14 -> 64 64 14 14")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Conv2d_2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 64 64 14 14 -> 64 64 7 7 ")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("MaxPool2d"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ReLU"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("view"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("64")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("14")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("14")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fc1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ReLU"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fc2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ReLU"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        x "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fc3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        self"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("num "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" x\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br"),t("span",{staticClass:"line-number"},[s._v("34")]),t("br"),t("span",{staticClass:"line-number"},[s._v("35")]),t("br"),t("span",{staticClass:"line-number"},[s._v("36")]),t("br"),t("span",{staticClass:"line-number"},[s._v("37")]),t("br"),t("span",{staticClass:"line-number"},[s._v("38")]),t("br"),t("span",{staticClass:"line-number"},[s._v("39")]),t("br"),t("span",{staticClass:"line-number"},[s._v("40")]),t("br"),t("span",{staticClass:"line-number"},[s._v("41")]),t("br"),t("span",{staticClass:"line-number"},[s._v("42")]),t("br"),t("span",{staticClass:"line-number"},[s._v("43")]),t("br"),t("span",{staticClass:"line-number"},[s._v("44")]),t("br"),t("span",{staticClass:"line-number"},[s._v("45")]),t("br"),t("span",{staticClass:"line-number"},[s._v("46")]),t("br"),t("span",{staticClass:"line-number"},[s._v("47")]),t("br"),t("span",{staticClass:"line-number"},[s._v("48")]),t("br")])]),t("ol",{attrs:{start:"3"}},[t("li",[s._v("编写训练和测试函数")])]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[s._v("lr "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.001")]),s._v("\ndevice "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("device"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'cuda'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("cuda"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("is_available"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'cpu'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nnum_classes "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 共有十种类别的数据图像")]),s._v("\n\nnet "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Conv2dModule"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("to"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("device"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\ncriterion "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" nn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CrossEntropyLoss"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 交叉熵损失函数")]),s._v("\noptimizer "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" optim"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Adam"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("parameters"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" lr"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("lr"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("getCudaData")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("tensor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("device"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" tensor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("to"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("device"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("float")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("train_fn")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("dataloader"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("device"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v("'''\n    返回整个过程的平均损失和模型准确率\n    '''")]),s._v("\n    loss_sum "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 损失函数值（总共）")]),s._v("\n    correct_num "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 预测与真实相符的数量")]),s._v("\n    sample_num "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 样本数量")]),s._v("\n    batch_sum "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("len")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("dataloader"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("train"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" batch_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("inputs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("labels"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("enumerate")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("dataloader"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        optimizer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("zero_grad"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        inputs "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" getCudaData"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("inputs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("device"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("float")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 交叉熵函数只对类型long支持")]),s._v("\n        labels "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" getCudaData"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("labels"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("device"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("long")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string-interpolation"}},[t("span",{pre:!0,attrs:{class:"token string"}},[s._v("f'inputs shape:")]),t("span",{pre:!0,attrs:{class:"token interpolation"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("inputs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shape"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")])]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n        labels_pre "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("inputs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        loss "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" criterion"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("labels_pre"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" labels"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        \n        loss"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("backward"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        optimizer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("step"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n        loss_sum "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+=")]),s._v(" loss"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("item"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 找出样本值里最大idx，定为预测值")]),s._v("\n        pre_index "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("argmax"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("labels_pre"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" dim"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        correct_num "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("pre_index "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" labels"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("sum")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("item"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        sample_num "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("len")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("labels"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    loss_avg "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" loss_sum "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" batch_sum\n    correct_rate "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" correct_num "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" sample_num\n\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" loss_avg"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" correct_rate\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("test_fn")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("dataloader"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("device"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v("'''\n    返回整个过程的平均损失和模型准确率\n    '''")]),s._v("\n    loss_sum "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 损失函数值（总共）")]),s._v("\n    correct_num "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 预测与真实相符的数量")]),s._v("\n    sample_num "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 样本数量")]),s._v("\n    batch_sum "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("len")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("dataloader"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    \n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("with")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("no_grad"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("eval")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" batch_id"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("inputs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" labels"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("enumerate")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("dataloader"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            inputs "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" getCudaData"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("inputs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" device"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("float")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            labels "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" getCudaData"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("labels"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" device"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("long")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n            labels_pre "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("inputs"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            loss "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" criterion"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("labels_pre"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" labels"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            loss_sum "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+=")]),s._v(" loss"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("item"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            \n            pre_index "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" torch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("argmax"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("labels_pre"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" dim"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            correct_num "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("pre_index "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" labels"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("sum")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("item"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n            sample_num "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("len")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("labels"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            \n    loss_avg "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" loss_sum "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" batch_sum\n    correct_rate "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" correct_num "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" sample_num\n        \n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" loss_avg"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" correct_rate\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br"),t("span",{staticClass:"line-number"},[s._v("34")]),t("br"),t("span",{staticClass:"line-number"},[s._v("35")]),t("br"),t("span",{staticClass:"line-number"},[s._v("36")]),t("br"),t("span",{staticClass:"line-number"},[s._v("37")]),t("br"),t("span",{staticClass:"line-number"},[s._v("38")]),t("br"),t("span",{staticClass:"line-number"},[s._v("39")]),t("br"),t("span",{staticClass:"line-number"},[s._v("40")]),t("br"),t("span",{staticClass:"line-number"},[s._v("41")]),t("br"),t("span",{staticClass:"line-number"},[s._v("42")]),t("br"),t("span",{staticClass:"line-number"},[s._v("43")]),t("br"),t("span",{staticClass:"line-number"},[s._v("44")]),t("br"),t("span",{staticClass:"line-number"},[s._v("45")]),t("br"),t("span",{staticClass:"line-number"},[s._v("46")]),t("br"),t("span",{staticClass:"line-number"},[s._v("47")]),t("br"),t("span",{staticClass:"line-number"},[s._v("48")]),t("br"),t("span",{staticClass:"line-number"},[s._v("49")]),t("br"),t("span",{staticClass:"line-number"},[s._v("50")]),t("br"),t("span",{staticClass:"line-number"},[s._v("51")]),t("br"),t("span",{staticClass:"line-number"},[s._v("52")]),t("br"),t("span",{staticClass:"line-number"},[s._v("53")]),t("br"),t("span",{staticClass:"line-number"},[s._v("54")]),t("br"),t("span",{staticClass:"line-number"},[s._v("55")]),t("br"),t("span",{staticClass:"line-number"},[s._v("56")]),t("br"),t("span",{staticClass:"line-number"},[s._v("57")]),t("br"),t("span",{staticClass:"line-number"},[s._v("58")]),t("br"),t("span",{staticClass:"line-number"},[s._v("59")]),t("br"),t("span",{staticClass:"line-number"},[s._v("60")]),t("br"),t("span",{staticClass:"line-number"},[s._v("61")]),t("br"),t("span",{staticClass:"line-number"},[s._v("62")]),t("br"),t("span",{staticClass:"line-number"},[s._v("63")]),t("br"),t("span",{staticClass:"line-number"},[s._v("64")]),t("br"),t("span",{staticClass:"line-number"},[s._v("65")]),t("br"),t("span",{staticClass:"line-number"},[s._v("66")]),t("br"),t("span",{staticClass:"line-number"},[s._v("67")]),t("br"),t("span",{staticClass:"line-number"},[s._v("68")]),t("br"),t("span",{staticClass:"line-number"},[s._v("69")]),t("br"),t("span",{staticClass:"line-number"},[s._v("70")]),t("br"),t("span",{staticClass:"line-number"},[s._v("71")]),t("br"),t("span",{staticClass:"line-number"},[s._v("72")]),t("br")])]),t("ol",{attrs:{start:"4"}},[t("li",[s._v("训练")])]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[s._v("train_loss_list "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\ntest_loss_list "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\ntrain_cro_rate_list "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\ntest_cro_rate_list "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n\nepoch "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" e "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("range")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("epoch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    train_loss"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" train_cro_rate"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" train_fn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("train_loader"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("device"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    train_loss_list"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("append"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("train_loss"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    train_cro_rate_list"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("append"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("train_cro_rate"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    test_loss"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" test_cro_rate"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" test_fn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("test_loader"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("net"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("device"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    test_loss_list"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("append"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("test_loss"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    test_cro_rate_list"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("append"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("test_cro_rate"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br")])]),t("ol",{attrs:{start:"5"}},[t("li",[s._v("画图")])]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[s._v("fig "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" plt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("figure"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("figsize"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nax1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" fig"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("add_subplot"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nax1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("plot"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("train_cro_rate_list"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" label"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'train'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nax1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("plot"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("test_cro_rate_list"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" label"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'test'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nax1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("set")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'cro_rate'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\nax2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" fig"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("add_subplot"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nax2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("plot"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("train_loss_list"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" label"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'train'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nax2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("plot"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("test_loss_list"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" label"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'test'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nax2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("title"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'loss'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nplt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("legend"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nplt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("show"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br")])]),t("p",[t("img",{attrs:{src:"markdown-img/%E4%BA%8C%E7%BB%B4%E5%8D%B7%E7%A7%AF.assets/%E4%BA%8C%E7%BB%B4%E5%8D%B7%E7%A7%AF_12_0.png",alt:"png"}})])])}),[],!1,null,null,null);t.default=e.exports}}]);